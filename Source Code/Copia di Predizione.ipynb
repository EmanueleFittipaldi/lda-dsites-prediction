{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia di Predizione.ipynb","provenance":[{"file_id":"1FaixPHOXiaS6yUho8l5lzVmRYZv27GM8","timestamp":1631370938063}],"collapsed_sections":[],"mount_file_id":"1FaixPHOXiaS6yUho8l5lzVmRYZv27GM8","authorship_tag":"ABX9TyN/9rx7hWfRyt+iHjLqbPIp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RRR4HJIZNp1W"},"source":["This notebook taks the CSV as an input. The CSV was obtained from the original Dataset containing all the reviews from the users for the apps on the store. I've applaied a simple pre-processing steps in order to obtain an homogeneous corpus to feed LDA. Once the model was trained I've used it to extract the Topic distribuition latent in every reveiw. The Topic distribuition represents my set of features on which I will train the classifier. This is a Multi-Class classification problem in which I have N possibile classes in which classify my samples and where every sample has a certain amount of features."]},{"cell_type":"code","metadata":{"id":"Nv9pVYtKw72G","executionInfo":{"status":"ok","timestamp":1631368123944,"user_tz":-120,"elapsed":1306,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}}},"source":["import pandas as pd\n","from sklearn import tree\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn import datasets\n","from sklearn import model_selection\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split # Import train_test_split function\n","from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n","from sklearn import metrics  #Import scikit-learn metrics module for accuracy calculation\n","from sklearn.linear_model import SGDClassifier\n","from sklearn import linear_model\n","from sklearn.metrics import classification_report\n","import numpy as np\n","import re\n","  \n","def strToList(dato):\n","  line = re.sub('[(,)]', '', dato).split(\" \") \n","  distribuzione=[]\n","  for x in range(1, 15):\n","   if(x%2)!=0:\n","    distribuzione.append(float(line[x]))\n","  return distribuzione  \n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iHPa1vUKmpvi"},"source":["First things first. Let's import the dataset and let's give a peak at the data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"v80Adtk1ijQs","executionInfo":{"status":"ok","timestamp":1631368132637,"user_tz":-120,"elapsed":3596,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"0449322a-8007-467f-da5e-24895d594bba"},"source":["data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/FinalDataset.csv\",error_bad_lines=False, sep=',')\n","data.head() # Shows me the first 5 rows of the data set\n","\n","#effettuo il drop di tutte quelle righe appartenenti a categorie espresse in modo composto\n","data = data[data.category != 'Connectivity,Development']\n","data = data[data.category != 'Connectivity,Theming']\n","data = data[data.category != 'Internet,Phone & SMS']\n","data = data[data.category != 'Internet,Reading']\n","data = data[data.category != 'Internet,Security']\n","data = data[data.category != 'Multimedia,Graphics']\n","data = data[data.category != 'Multimedia,Theming']\n","data = data[data.category != 'Phone & SMS']\n","data = data[data.category != 'Phone & SMS,Internet']\n","data = data[data.category != 'Phone & SMS,Multimedia']\n","data = data[data.category != 'Phone & SMS,Security']\n","data = data[data.category != 'Reading,Multimedia']\n","data = data[data.category != 'Science & Education']\n","data = data[data.category != 'Science & Education,Time']\n","data = data[data.category != 'Security,Internet']\n","data = data[data.category != 'Sports & Health']\n","data = data[data.category != 'System,Time']\n","data = data[data.category != 'Time,Writing']\n","data = data[data.category != 'System,Development']\n","data = data[data.category != 'Money']\n","data = data[data.category != 'Time']\n","data = data[data.category != 'Writing']\n","data = data[data.category != 'Graphics']\n","data = data[data.category != 'Development']\n","\n","#converto i nomi delle classi rimanenti label numeriche\n","\n","\n","\n","data.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>category</th>\n","      <th>TopicDistribuition</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>97</th>\n","      <td>Crippling power consumption The devs really ne...</td>\n","      <td>Internet</td>\n","      <td>[(0, 0.020833334), (1, 0.5208332), (2, 0.02083...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>Unusable in large rooms No way to filter out j...</td>\n","      <td>Internet</td>\n","      <td>[(0, 0.0625), (1, 0.0625), (2, 0.0625), (3, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>is there a way to hide channel list when using...</td>\n","      <td>Internet</td>\n","      <td>[(0, 0.03125), (1, 0.53114474), (2, 0.03125), ...</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>+1 star for finally including auto-reconnect  ...</td>\n","      <td>Internet</td>\n","      <td>[(0, 0.008928572), (1, 0.232126), (2, 0.366071...</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>Material design update very nice</td>\n","      <td>Internet</td>\n","      <td>[(0, 0.3750001), (1, 0.041666668), (2, 0.04166...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                review  ...                                 TopicDistribuition\n","97   Crippling power consumption The devs really ne...  ...  [(0, 0.020833334), (1, 0.5208332), (2, 0.02083...\n","98   Unusable in large rooms No way to filter out j...  ...  [(0, 0.0625), (1, 0.0625), (2, 0.0625), (3, 0....\n","99   is there a way to hide channel list when using...  ...  [(0, 0.03125), (1, 0.53114474), (2, 0.03125), ...\n","100  +1 star for finally including auto-reconnect  ...  ...  [(0, 0.008928572), (1, 0.232126), (2, 0.366071...\n","101                   Material design update very nice  ...  [(0, 0.3750001), (1, 0.041666668), (2, 0.04166...\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"OG-_Cs95m0yz"},"source":["I don't need the 'Review' column anymore. I have to extract 'category' and 'TopicDistribuition' column. I start extracting 'TopicDistribuition' first since I need to convert each string into a probability distribuition. So I took the 'TopicDistribuitions' column and transfer it into a list called 'temp'. 'temp' is a list of strings where each string represent a probability distribuition. I need just the numbers, so I need to convert each string."]},{"cell_type":"code","metadata":{"id":"uR1D-yaSitxh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631368150019,"user_tz":-120,"elapsed":308,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"9d3874f3-9477-4c58-dd27-36d927ba5deb"},"source":["temp=data.TopicDistribuition.tolist()\n","print(\"Converto la colonna Topic Distribuition in una lista\")\n","print(temp[:5])"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Converto la colonna Topic Distribuition in una lista\n","['[(0, 0.020833334), (1, 0.5208332), (2, 0.020833334), (3, 0.020833334), (4, 0.020833334), (5, 0.020833334), (6, 0.020833334), (7, 0.35416678)]', '[(0, 0.0625), (1, 0.0625), (2, 0.0625), (3, 0.0625), (4, 0.0625), (5, 0.5625), (6, 0.0625), (7, 0.0625)]', '[(0, 0.03125), (1, 0.53114474), (2, 0.03125), (3, 0.031355355), (4, 0.2812499), (5, 0.03125), (6, 0.03125), (7, 0.03125)]', '[(0, 0.008928572), (1, 0.232126), (2, 0.36607176), (3, 0.28570276), (4, 0.08035694), (5, 0.008928572), (6, 0.0089470735), (7, 0.008938288)]', '[(0, 0.3750001), (1, 0.041666668), (2, 0.041666668), (3, 0.3749999), (4, 0.041666668), (5, 0.041666668), (6, 0.041666668), (7, 0.041666668)]']\n"]}]},{"cell_type":"markdown","metadata":{"id":"ClTapCHQpAQS"},"source":["In order to convert each string into a proper list of floats I am using the 'strToList' function"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4jRIJ5aiwqT","executionInfo":{"status":"ok","timestamp":1631368157102,"user_tz":-120,"elapsed":3576,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"6277f950-6f3e-40f3-f106-ef3e79ac57db"},"source":["x = [strToList(x) for x in temp ]\n","print(\"Conversione di temp in una lista di distribuzioni di probabilità\")\n","print(x[:10])\n","\n","#ho aggiunto questa conversione perchè sospetto che il fatto di averlo avuto sottoforma di lista abbia inficiato l'accuratezza\n","x=np.array([np.array(xi) for xi in x])\n","print(type(x))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Conversione di temp in una lista di distribuzioni di probabilità\n","[[0.020833334, 0.5208332, 0.020833334, 0.020833334, 0.020833334, 0.020833334, 0.020833334], [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.5625, 0.0625], [0.03125, 0.53114474, 0.03125, 0.031355355, 0.2812499, 0.03125, 0.03125], [0.008928572, 0.232126, 0.36607176, 0.28570276, 0.08035694, 0.008928572, 0.0089470735], [0.3750001, 0.041666668, 0.041666668, 0.3749999, 0.041666668, 0.041666668, 0.041666668], [0.34375042, 0.17708302, 0.09375009, 0.010416666, 0.09374999, 0.010416666, 0.093749575], [0.5114528, 0.03126889, 0.031254027, 0.3010243, 0.03125, 0.03125, 0.03125], [0.28124994, 0.03125, 0.031261522, 0.03125, 0.53123856, 0.03125, 0.03125], [0.015625, 0.14062455, 0.26562533, 0.26562467, 0.015625, 0.015625, 0.14062524], [0.51040554, 0.01042255, 0.010420013, 0.010422617, 0.17707926, 0.09375002, 0.17708336]]\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"markdown","metadata":{"id":"sS4Dm0KqpWC5"},"source":["I need to obtain the labels too in a separate vector. I do so by saving them into the vector called 'y'"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPhkFmEjpUqU","executionInfo":{"status":"ok","timestamp":1631368166662,"user_tz":-120,"elapsed":685,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"13726a65-b790-4d60-e367-dfd510d69473"},"source":["y = data.category.tolist()\n","print(\"print della lista y contenente le categorie\")\n","y=np.array([np.array(xi) for xi in y])\n","print(type(y))\n","print(y)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["print della lista y contenente le categorie\n","<class 'numpy.ndarray'>\n","['Internet' 'Internet' 'Internet' ... 'Reading' 'Reading' 'Reading']\n"]}]},{"cell_type":"markdown","metadata":{"id":"z9dtq34KpsaJ"},"source":["Here I wanted to make sure that I had the same number of labels as the number of the probability distribuitions"]},{"cell_type":"code","metadata":{"id":"mtClK2UfprAr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631368169903,"user_tz":-120,"elapsed":214,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"a82ce123-f145-4238-eeb9-58f888a62893"},"source":["print(\"numero di distribuzioni di probabilità: \"+str(len(x)))\n","print(\"numero di label: \"+str(len(y)))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["numero di distribuzioni di probabilità: 253071\n","numero di label: 253071\n"]}]},{"cell_type":"markdown","metadata":{"id":"2bJQ9v6zp6Ia"},"source":["That's a first attempt in creating a new cleaned version of the original Dataset where TopicDistribuitions column had not strings but actual vectors of floats"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"Qjy-O6K_izaY","executionInfo":{"status":"ok","timestamp":1631368557455,"user_tz":-120,"elapsed":245,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"4d7f65a2-adf6-4dcb-99e6-542543136abe"},"source":["#questo codice funziona quando x e y non sono di tipo ndarray, ma adesso che li ho convertiti in questo tipo\n","#la colonna TopicDistribuitions non me la da più correttamente, ma questo poco importa perchè non uso newDataFrame\n","#questo codice faceva soltanto parte di una mia congettura per capire come aumentare l'accuracy.\n","my_column_names=['Reviews','TopicDistribuitions']\n","newDataFrame=pd.DataFrame(columns=my_column_names)\n","newDataFrame['Reviews']=y\n","newDataFrame['TopicDistribuitions']=x\n","newDataFrame.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Reviews</th>\n","      <th>TopicDistribuitions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Internet</td>\n","      <td>0.020833</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Internet</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Internet</td>\n","      <td>0.031250</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Internet</td>\n","      <td>0.008929</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Internet</td>\n","      <td>0.375000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Reviews  TopicDistribuitions\n","0  Internet             0.020833\n","1  Internet             0.062500\n","2  Internet             0.031250\n","3  Internet             0.008929\n","4  Internet             0.375000"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"lHI2mORNqIJh"},"source":["I suspected that in order to train the model properly I had to explicitate each Topic as a feature in a separate column. That's why I created another DataSet from the previously DataSet"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYH-Jm_ni2xl","executionInfo":{"status":"ok","timestamp":1631370907158,"user_tz":-120,"elapsed":213,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"f10930c8-a721-4668-c4f8-310cd62fdb8c"},"source":["my_column_names=['Topic0','Topic1','Topic2','Topic3','Topic4','Topic5','Topic6']\n","new_DataFrame=pd.DataFrame(x,columns=my_column_names)\n","new_DataFrame['Category']=y\n","\n","new_DataFrame=pd.get_dummies(new_DataFrame)\n","new_DataFrame.head()\n","#new_DataFrame.corr() #per generare la matrice di correlazione\n","\n","features=new_DataFrame[[\"Topic0\", \"Topic1\", \"Topic2\", \"Topic3\", \"Topic4\", \"Topic5\", \"Topic6\"]].to_numpy()\n","lables=new_DataFrame[[\"Category_Connectivity\", \"Category_Games\", \"Category_Internet\", \"Category_Multimedia\", \"Category_Navigation\", \"Category_Reading\", \"Category_Security\",\"Category_System\",\"Category_Theming\"]].to_numpy()\n"],"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 1 ... 0 0 0]\n"," [0 0 1 ... 0 0 0]\n"," [0 0 1 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"yPrAD-LL6EEd"},"source":["Actual splitting into a test set, training set (and validation set?)"]},{"cell_type":"code","metadata":{"id":"UgZiKtKqi5hp","executionInfo":{"status":"ok","timestamp":1631370815545,"user_tz":-120,"elapsed":224,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(features, lables, test_size=0.2, random_state=1) # 70% training set and 30% test set\n","\n","Z_train, Z_test, W_train, W_test = train_test_split(X_train, y_train, test_size=0.4, random_state=1) # 70% training set subset and 30% validation set"],"execution_count":75,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kj_O0JTPjzNE"},"source":["Creating a Decision tree classifier object"]},{"cell_type":"code","metadata":{"id":"SQKJ5UGNi6Wn","executionInfo":{"status":"ok","timestamp":1631370817151,"user_tz":-120,"elapsed":219,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}}},"source":["clf = DecisionTreeClassifier(criterion=\"gini\",max_depth=10)"],"execution_count":76,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAr6JMr-jsa7"},"source":["Now I train the decision tree classifier"]},{"cell_type":"code","metadata":{"id":"oqihrFeoi6-L","executionInfo":{"status":"ok","timestamp":1631370819097,"user_tz":-120,"elapsed":834,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}}},"source":["clf = clf.fit(Z_train,W_train)"],"execution_count":77,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKMmHVjnjaBD"},"source":["Now I test the model on the test set held out in the beginning"]},{"cell_type":"code","metadata":{"id":"bHiGSpF4i7yx","executionInfo":{"status":"ok","timestamp":1631370820420,"user_tz":-120,"elapsed":233,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}}},"source":["y_pred = clf.predict(Z_test)"],"execution_count":78,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FFi5fJfXjIxC"},"source":["Now I measure model accuracy which means how often the classifier is correct"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0dK7D3n1jGwM","executionInfo":{"status":"ok","timestamp":1631370830812,"user_tz":-120,"elapsed":236,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"008114b5-639a-4987-d216-afc8ddff7624"},"source":["print(\"Accuracy:\",metrics.accuracy_score(W_test, y_pred)*100,str(\"%\"))\n","report = classification_report(W_test, y_pred)\n","print(report)"],"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 31.70171517478977 %\n","              precision    recall  f1-score   support\n","\n","           0       0.33      0.00      0.00       888\n","           1       0.62      0.03      0.06      7960\n","           2       0.55      0.02      0.03     15272\n","           3       0.22      0.00      0.01      6071\n","           4       0.59      0.72      0.65     34890\n","           5       0.00      0.00      0.00      2664\n","           6       0.00      0.00      0.00      2244\n","           7       0.36      0.01      0.02      9327\n","           8       0.20      0.00      0.00      1667\n","\n","   micro avg       0.58      0.32      0.41     80983\n","   macro avg       0.32      0.09      0.08     80983\n","weighted avg       0.48      0.32      0.29     80983\n"," samples avg       0.32      0.32      0.32     80983\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-2F-tjqtz2K","executionInfo":{"status":"ok","timestamp":1631370665374,"user_tz":-120,"elapsed":38830,"user":{"displayName":"EMANUELE FITTIPALDI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16633094148140330458"}},"outputId":"8de60ee8-2ed5-4258-e612-a1b58c7a3df1"},"source":["#con kfold e usando la metrica di accuracy\n","kfold = model_selection.KFold(n_splits=10, random_state=10, shuffle=True)\n","scoring_0 = 'accuracy' #accuracy\n","results_0 = model_selection.cross_val_score(LogisticRegression(solver='liblinear'), x, y, cv=kfold, scoring=scoring_0)\n","print(\"accuracy: %.3f (%.3f)\" % (results_0.mean(), results_0.std()))\n"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy: 0.438 (0.003)\n"]}]}]}